% EPA5.TEX (RMCG20010122)

\Section El problema aparente formalizado

Utilizando el ^{álgebra automática} para formalizar el ^{problema
aparente}, la ^{solución} buscada ha de ser un ^{autómata} finito y
probabilístico, o sea, un ^{comportamiento}, que denominaremos~$\aut A$,
y que en el problema ocupa el lugar de la ^{incógnita}, por lo que lo
anotaremos~$\aut A?$. Del ^{universo}, que notaremos~$\aut U$, sabemos
que es otro autómata finito y probabilístico, pero nada más, de manera
que puede ser cualquier autómata finito y probabilístico, lo que se
indica $\forall \aut U$. Además, sabemos que en el problema aparente la
incógnita y el universo interactúan. Por último, hay que comprobar que
las reacciones del universo son buenas, para lo que utilizaremos una
^{medición} conocida que será otro autómata finito y probabilístico,
{\Metric}.

Todos estos autómatas dibujan el siguiente circuito que representa el
^{problema aparente formalizado} en el álgebra automática (\EPA{1.4.1}).
% Interacción total y medida externa
$$\MTbeginchar(110pt,70pt,0pt);
 \MT: pickup thick_pen;
 \MT: x1 + x2 = w; x2 = x1 + 50u; y1b = y2b = 30v;
 \MT: rectangle(1)(20u,20v); % 1 is U
 \MT: rectangle(2)(20u,20v); % 2 es A
 \MT: z1lbl = z1; z2lbl = z2;
 \MTlabel(1lbl)"$\forall \aut U$";
 \MTlabel(2lbl)"$\aut A ?$";
 \MT: z3o = (x2r,y2); z3d = (x1l,y1);
 \MT: feedback(3,3o,3d)(h,10u,10u);
 \MT: x3lbl.l = x3br; y3lbl.t = y3br - jot;
 \MTlabel(3lbl)"\no m";
 \MT: x4tl = x1r; x4tr = x2l; y4tl = 2/3[y1b,y1t]; y4tr = 2/3[y2b,y2t];
 \MT: x4bl = x1r; x4br = x2l; y4bl = 1/3[y1b,y1t]; y4br = 1/3[y2b,y2t];
 \MT: arrow(4tl,4tr); arrow(4bl,4br); % arrows from U to A
 \MT: x4tlbl = x4tr - 10u; y4tlbl.b = y4tr + jot;
 \MT: x4blbl = x4tlbl; y4blbl.t = y4br - jot;
 \MTlabel(4tlbl)"\no n"; \MTlabel(4blbl)"\no v";
 \MT: pickup thick_pen;
 \MT: z6 = z2 - (0,30v); z6lbl = z6;
 \MT: rectangle(6)(20u,20v); % 6 is M
 \MTlabel(6lbl)"\Metric";
 \MT: pickup med_pen;
 \MT: z7o = 1/6[z4bl,z4br]; z7d = (x6l,y6); z7m = z7d - (10u,0);
 \MT: fork(7o,7m,7d);
 \MT: x7lbl = x7m; y7lbl.t = y7m - jot;
 \MTlabel(7lbl)"\no v";
 \MT: z8l = (x6r,y6); z8r = (w,y6); arrow(8l,8r);
 \MT: x8lbl = x3lbl; y8lbl.t = y6 - jot;
 \MTlabel(8lbl)"\sevenbf 1";
\MTendchar;
\box\MTbox$$

La letra negrilla~$\no n$ indica la parte de los ^{datos de entrada} que
no influye directamente en la solución del problema; son los ^{datos
neutros}. Los ^{datos} de entrada que sí influyen están señalados con la
letra negrilla~$\no v$; son los ^{datos valorados}. Los ^{datos de
salida} están señalados con la letra negrilla~$\no m$.

La ^{medición} {\Metric} utiliza una copia de los datos valorados~$\no
v$ y en cuanto su salida tome el valor $0$, el autómata \aut A habrá
fracasado como solución del problema. De {\Metric} solamente hemos dicho
que es un autómata conocido, lo que resulta demasiado genérico. Para
fijar las explicaciones tomaremos un caso válido pero sencillo de
{\Metric}: pone a su salida un $1$ si a su entrada, en ese instante, son
mayoría los valores $1$, y un $0$ si no.

Así las cosas, la solución del problema, $\aut A$, deberá ser capaz de
generar en cada instante, y sea como sea $\aut U$, una mayoría de
valores~$1$ en los datos valorados~$\no v$. De todo el ^{problema
aparente formalizado}, en esto lo hemos dejado, y con esto es suficiente
para seguir las explicaciones que vienen.
% Interacción total con semántica mínima
$$\MTbeginchar(100pt,40pt,0pt);
 \MT: pickup thick_pen;
 \MT: x1 + x2 = w; x2 = x1 + 40u; y1b = y2b = 0;
 \MT: rectangle(1)(20u,20v); % 1 is U
 \MT: rectangle(2)(20u,20v); % 2 es A
 \MT: z1lbl = z1; z2lbl = z2;
 \MTlabel(1lbl)"$\forall \aut U$";
 \MTlabel(2lbl)"$\aut A ?$";
 \MT: z3o = (x2r,y2); z3d = (x1l,y1);
 \MT: feedback(3,3o,3d)(h,10u,10u);
 \MT: x3lbl.l = x3br; y3lbl.t = y3br - jot;
 \MTlabel(3lbl)"\no m";
 \MT: x4tl = x1r; x4tr = x2l; y4tl = 2/3[y1b,y1t]; y4tr = 2/3[y2b,y2t];
 \MT: x4bl = x1r; x4br = x2l; y4bl = 1/3[y1b,y1t]; y4br = 1/3[y2b,y2t];
 \MT: arrow(4tl,4tr); arrow(4bl,4br); % arrows from U to A
 \MT: x4tlbl = 1/2[x4tl,x4tr]; y4tlbl.b = 1/2[y4tl,y4tr] + jot;
 \MT: x4blbl = 1/2[x4bl,x4br]; y4blbl.t = 1/2[y4bl,y4br] - jot;
 \MTlabel(4tlbl)"\no n"; \MTlabel(4blbl)"\no v";
\MTendchar;
\box\MTbox
\abovedisplayskip=0pt plus 3pt
\belowdisplayskip=0pt minus 6pt
$$


\Section La notación

Puede que a usted le incomoden las letras caligráficas que acompañan a
algunas palabras. Sirven para señalar los conceptos formales definidos
matemáticamente y, así, por ejemplo, con un simple golpe de vista, puede
usted determinar que el {\cuerpo} al que me refiero es el cuerpo
definido en la teoría, y no otro. Merecen ser toleradas porque reducen
la ambigüedad del texto a cambio de entorpecer algo la lectura o,
incluso, a cambio de nada si, con un poco de ejercicio, aprende usted a
ignorarlas.

Y, con estas precisiones, estamos ya en disposición de resolver el
^{problema aparente formalizado}, como nos habíamos propuesto en ^>La
evolución y la resolución>. Recordemos que se trata de diseñar un
^{autómata}~\aut A capaz de generar en cada instante, y sea como sea el
^{universo}~\aut U al que se enfrente, una mayoría de valores~$1$ en los
^{datos valorados}~{\no v}.
 $$\hbox{Problema aparente formalizado} \etapa
   \hbox{Resolución}
\abovedisplayskip=12pt minus 3pt
\belowdisplayskip=0pt plus 3pt
$$


\Section El mecanismo formal

Para formalizar que nada se sabe del ^{universo}, hemos dicho que el
{\universo} podía ser cualquier ^{autómata} finito. Puede ser, por
ejemplo, el autómata que siempre produce a su salida valores~$0$. A este
{\universo} que sólo produce valores $0$ lo denominaremos \corporal
universo$U_0$. Y al que siempre produce valores~$1$, que también podría
ser ya que puede ser cualquiera, lo denominaremos \corporal
universo$U_1$.

\penalty-5000

Pues bien, dado que el {\universo} puede ser cualquiera, también podría
ser el \corporal universo$U_0$. Y si el {\universo} fuera el \corporal
universo$U_0$, entonces ningún autómata~$\aut A$ podría solucionar el
problema, porque nunca habría mayoría de valores~$1$ en los datos
valorados. Justo lo contrario es lo que sucedería si el {\universo}
fuera el benévolo \corporal universo$U_1$, ya que, entonces, cualquier
\corporal autómata$A$ lo solucionaría.

Ocurre, pues, que el ^{problema aparente formalizado} no tiene una
^{solución} definitiva, sino que depende de cómo sea el {\universo} del
que nada sabemos. Esto no nos descubre nada nuevo, excepto que la
formalización conserva esta característica fundamental del problema
aparente, a saber, que el problema aparente es paradójico, tal como
hemos visto en ^>La vida es paradójica>.

Estupendo, pero ¿cómo resolver el problema con tanta indeterminación?
Aunque no haya una solución definitiva válida en cualquier posible
{\universo}, cada \corporal autómata$A$ concreto lo solucionará en
determinados \corporal universos$U$ del total de los posibles. Tomemos
dos autómatas, por ejemplo~$\aut A_a$ y~$\aut A_b$, y supongamos que el
autómata~$\aut A_b$ soluciona el problema en todos los universos
posibles en los que el autómata~$\aut A_a$ lo soluciona y, además, en
otros. En este caso podemos afirmar que, a pesar de todas las
indeterminaciones, el autómata~$\aut A_b$ es mejor que el autómata~$\aut
A_a$.

Lo que vamos a hacer, pues, para resolver cada vez mejor el problema
aparente formalizado, será mostrar que, si un determinado autómata lo
soluciona en ciertos universos, entonces podemos construir otro autómata
que también lo soluciona en esos mismos universos y, por añadidura, en
otros (\EPA{1.5}). Y, para empezar la secuencia, tomaremos un autómata
cualquiera, al que denominaremos ^|mecanismo|, y que notaremos
como~$\aut A_0$ porque nos servirá de referencia. La forma del
{\mecanismo} es la mínima suficiente para poder ocupar el lugar de la
^{incógnita}~$\aut A?$ en el problema aparente formalizado (\EPA{1.6}).
% Mecanismo
$$\MTbeginchar(80pt,20pt,0pt);
 \MT: pickup thick_pen;
 \MT: x1 = w/2; y1b = 0; z1lbl = z1;
 \MT: rectangle(1)(20u,20v); % 1 is A_0
 \MTlabel(1lbl)"${\aut A}_0$";
 \MT: pickup med_pen;
 \MT: z2o = (0,1/3[y1b,y1t]); z2d = (x1l, y2o); arrow(2o,2d);
 \MT: z3o = (0,2/3[y1b,y1t]); z3d = (x1l, y3o); arrow(3o,3d);
 \MT: y2lbl.t = y2.o - jot; y3lbl.b = y3.o + jot;
 \MT: x2lbl = 1/2[x2o,x2d]; x3lbl = 1/2[x3o,x3d];
 \MTlabel(2lbl)"\no v"; \MTlabel(3lbl)"\no n";
 \MT: z4o = (x1r,1/2[y1b,y1t]); z4d = (w, y4o); arrow(4o,4d);
 \MT: y4lbl.t = y4o - jot; x4lbl = 1/2[x4o,x4d];
 \MTlabel(4lbl)"\no m";
\MTendchar;
\box\MTbox
$$


\Section El adaptador formal

El {\mecanismo} tiene un comportamiento que solucionará determinados
\corporal universos$U$, de modo que un {\adaptador} capaz de comportarse
como el {\mecanismo} y, además, de otras maneras, podrá solucionar más
universos. Esta observación nos permite diseñar un {\adaptador} que
mejora al {\mecanismo}. Veámoslo.

\penalty-5000

El ^|adaptador|~$\aut A_1$ se compone de un {\cuerpo}, capaz de varios
comportamientos, y de un {\gobernador}, que elige cuál de los
comportamientos se ejecuta.

\point El ^|cuerpo|~$\aut B$ es un autómata capaz de comportarse como el
{\mecanismo} y, además, de otras maneras, por lo que es, técnicamente,
una ^{ampliación} del {\mecanismo}. Aunque aquí no nos interesan los
tecnicismos, es importante conocer que dado cualquier autómata finito es
siempre posible construir una ampliación de él y, puesto que no depende
de condición alguna, decimos que el diseño del {\cuerpo} está
especificado.

\point El ^|gobernador|~$\aut G$ es otro autómata cuyo cometido es
disponer el ^{comportamiento} del {\cuerpo}. El diseño del {\gobernador}
no está especificado, pero si cumple una condición, que llamaremos
condición del gobernador, entonces el {\adaptador} soluciona, por lo
menos, todos los \corporal universos$U$ que el {\mecanismo} también
soluciona y, en consecuencia, queda asegurado que el {\adaptador} es tan
bueno o mejor que el {\mecanismo}. La ^{condición del gobernador} se
verifica si, cuando el {\adaptador} se enfrenta a un {\universo} que el
{\mecanismo} soluciona, su {\gobernador} manda que el {\cuerpo} se
comporte, precisamente, como el {\mecanismo}.

\noindent Por último, para que el {\gobernador} esté en la mejor de las
disposiciones para cumplir la condición del gobernador, debe recibir
todos los ^{datos}. Así alcanzamos a definir la forma del {\adaptador}
(\EPA{2}).
% Adaptador
$$\MTbeginchar(140pt,60pt,0pt);
 \MT: pickup thick_pen;
 \MT: x1r = w - 20u; y1b = 0; z1lbl = z1;
 \MT: rectangle(1)(20u,20v); % 1 is B
 \MTlabel(1lbl)"\aut B";
 \MT: x2r = x1l - 40u; y2b = y1t; z2lbl = z2;
 \MT: rectangle(2)(20u,20v); % 2 is G
 \MTlabel(2lbl)"\aut G";
 \MT: z3o = (x1r+5u,y1); z3d = (x2l,3/4[y2b,y2t]);
 \MT: forkback(3,3o,3d)(h,10u,10u);
 \MT: x3lbl.l = x3o; y3lbl.t = y3o - jot;
 \MTlabel(3lbl)"\no m";
 \MT: z4o = (x1r,y1); z4d = (w,y1); arrow(4o,4d);
 \MT: z6o = (0,1/4[y1b,y1t]); z6d = (x1l, y6o); arrow(6o,6d);
 \MT: z7o = (0,2/4[y1b,y1t]); z7d = (x1l, y7o); arrow(7o,7d);
 \MT: y6lbl.t = y6.o - jot; y7lbl.b = y7.o + jot; x6lbl = x7lbl = 5u;
 \MTlabel(6lbl)"\no v"; \MTlabel(7lbl)"\no n";
 \MT: z8d = (x2l,1/4[y2b,y2t]); z9d = (x2l,2/4[y2b,y2t]);
 \MT: z8m = z8d - (10u,0); z9m = z9d - (10u,0);
 \MT: z8o = (10u,y6o); fork(8o,8m,8d);
 \MT: z9o = (x8o,y7o); fork(9o,9m,9d);
 \MT: z10o = (x2r,y2); z10m = z10o + (5u,0);
 \MT: z10d = (x1l,3/4[y1b,y1t]); z10n = z10d - (10u,0);
 \MT: arrowww(10o,10m,10n,10d);
 \MT: x10lbl.l = x10m; y10lbl.b = y10m + jot;
 \MTlabel(10lbl)"\no b";
\MTendchar;
\box\MTbox$$

Aquí hemos utilizado un autómata, el {\cuerpo}, con varios
comportamientos, como adelantamos en ^>El comportamiento>. Los
datos~$\no b$, que son los que elabora el {\gobernador}, constituyen el
^{programa} del {\cuerpo}, mientras que los datos neutros~$\no n$ y los
valorados~$\no v$ son, en este caso, los datos de entrada ordinarios.


\Section Comparación de adaptadores

Para mostrar que efectivamente se verifica la equivalencia, propuesta en
^>La evolución y la resolución>, entre la resolución del problema
aparente y la evolución darviniana, veremos que el {\adaptador} formal
se corresponde con el adaptador evolutivo presentado entre _>El
adaptador> y _>La realidad del adaptador es objetiva> del camino de
entrada.

Un {\adaptador} formal es un autómata finito dividido en dos partes, un
{\cuerpo} capaz de varios comportamientos y un {\gobernador} que elige
el comportamiento del cuerpo. Así definido, este {\adaptador}
formalizado se parece poco al adaptador evolutivo que interponía una red
de objetos entre el fenómeno y la acción. Lo que sucede es que el
{\adaptador} resolutivo y formal es más general que el adaptador
evolutivo de entrada, al que incluye. Porque el adaptador evolutivo
elegía el comportamiento en función de los objetos presentes y, por lo
tanto, la percepción, que era la parte que determinaba qué objetos
estaban presentes, era la que, al determinarlos, elegía el
comportamiento del adaptador. De modo que, según la formalización
efectuada, la percepción hace la función de {\gobernador}, pero de una
manera concreta, usando objetos.

La relación entre ambos adaptadores queda patente al indicar, sobre el
diagrama del adaptador evolutivo mostrado en ^>El adaptador>, las partes
del {\adaptador} formal que realizan el tratamiento de los datos
representado por cada flecha.
$$\hbox{Fenómeno}
  \underbrace{
   \base{$\aut G\;\;$\cr$\longrightarrow\;$}
   \hbox{\strut Objeto}
   \base{$\aut B$\cr$\;\longrightarrow$}}_{\hbox{\strut Adaptador}}
  \hbox{Acción}
$$


\Section La mejora del cuerpo

La resolución formal del problema aparente nos llevó del {\mecanismo},
con un solo comportamiento, al {\adaptador}, que lo mejoraba porque era
capaz de varios comportamientos. Del mismo modo puede un {\adaptador}
mejorar a otro si es capaz de más comportamientos. No hay mucho más que
decir de esta línea de resolución de mejora cuantitativa, que tiende a
aumentar la versatilidad del {\cuerpo}, pero no debe olvidarse cuando
demos el próximo salto cualitativo, aunque sea mucho más espectacular.


\Section La previsión

Al definir el {\adaptador} formal, su {\cuerpo} quedó especificado,
pero, en cambio, de su {\gobernador} solamente establecimos una
condición suficiente para mejorar al {\mecanismo}, la ^{condición del
gobernador}. Así que ahora, para diseñar un {\aprendiz} que mejore al
{\adaptador}, nos centraremos en la mejora del {\gobernador}.

La tarea del {\gobernador}, que consiste en elegir el comportamiento del
{\cuerpo}, puede hacerse de varios modos. Si el {\universo} fuera
completamente conocido, que no es el caso frente a un problema aparente,
entonces se podría diseñar un {\gobernador} que eligiera
sistemáticamente el comportamiento óptimo, sin errar jamás y, por
consiguiente, sin necesidad de rectificar nunca su elección.
Denominaremos, a cualquier gobernador que no rectifica, ^{gobernador
mecánico}. En el otro extremo se encuentra el ^{homeostato} de
^[Ashby]^(Ashby1956), que elige el comportamiento al azar, pero que
rectifica el comportamiento, eligiendo otro igualmente al azar, en
cuanto la valoración obtenida no alcanza un determinado umbral. De esta
manera, es seguro que sólo son estables aquellos comportamientos del
homeostato cuya valoración supera dicho umbral.

Puede establecerse un continuo desde el gobernador mecánico, que nunca
rectifica, hasta el homeostato, que todo lo fía a la rectificación, ya
que elige sin criterio. Llamaremos tanteador_{tantear} a aquel
{\gobernador} que tantea, es decir, que emplea un procedimiento de
prueba y error. El homeostato es un ejemplo extremo de tanteador.

Un {\gobernador} que tantea no prevé, sino que intenta un comportamiento
y, si éste no soluciona, prueba otro. Peor es el caso del {\gobernador}
mecánico que, además de no prever, es incapaz de rectificar si el
comportamiento es malo, como sí hace el que tantea. Una manera mejor de
elegir el comportamiento consiste en prever_{previsión} su efecto antes
de ejecutarlo, porque, si el pronóstico es exacto, evita sufrir los
errores inherentes a los procedimientos de prueba y error. Así que la
diferencia entre un {\aprendiz} y un {\adaptador} será que el
{\aprendiz} prevé el futuro, y el {\adaptador} no. Para prever el
resultado de ejecutar un comportamiento es preciso disponer internamente
de un modelo del exterior, modelo que llamaremos {\realidad}. Y, con
estos razonamientos, ya podemos diseñar un {\aprendiz}.


\Section El aprendiz formal

El ^|aprendiz|~$\aut A_2$ tiene tres partes: un {\cuerpo}, capaz de
varios comportamientos, un {\modelador}, que modela el exterior, y un
{\simulador}, que elige el comportamiento actual valiéndose del modelo
para hacer pronósticos con los que compara los comportamientos posibles.

\point El {\cuerpo} del {\aprendiz} es capaz de varios comportamientos,
cuantos más mejor, según hemos visto en ^>La mejora del cuerpo>, pero al
menos y para superar al {\adaptador}, todos los de éste. Técnicamente,
el {\cuerpo} del {\aprendiz} es una ^{ampliación} del {\cuerpo} del
{\adaptador} y, por consiguiente, su diseño está especificado.

\point La tarea del ^|modelador|~$\aut M$ consiste en buscar un modelo
del {\universo} exterior, modelo que denominamos ^|realidad|~$\aut R$.
El {\modelador} observa las acciones que el propio {\aprendiz} realiza
sobre el {\universo} y las reacciones de éste, y, con estos datos,
elabora la realidad, que es un comportamiento, o sea, un autómata~$\aut
R$. Si la {\realidad} es indistinguible del {\universo} exterior,
entonces sirve para hacer pronósticos acertados y decimos que se cumple
la ^{condición del modelador}.

\point El ^|simulador|~$\aut S$ dispone el comportamiento y, para
elegirlo, puede utilizar la {\realidad} y así prever_{previsión} sus
consecuencias antes de ejecutarlo. La simulación es completamente
interna al {\aprendiz}; recibe la {\realidad} del {\modelador} y entrega
el comportamiento al {\cuerpo}; y, por esta razón, su diseño está
completamente especificado.

\noindent La condición del modelador es una condición suficiente para
que el {\aprendiz} supere al {\adaptador}. Porque, si se cumple la
condición del modelador, o sea, si los pronósticos de la {\realidad} son
acertados, entonces el {\aprendiz} puede simular perfectamente la
situación a la que se enfrenta el {\adaptador} que está intentando
superar, pero con la ventaja de evitar la ejecución actual contra el
{\universo} exterior de los comportamientos previsiblemente peores, que
coinciden con los comportamientos peores porque estamos suponiendo que
los pronósticos son certeros.

\breakif6

La forma del {\aprendiz} es la que muestra la figura siguiente (\EPA3).
% Aprendiz
$$\MTbeginchar(170pt,60pt,0pt);
 \MT: pickup thick_pen;
 \MT: x1r = w - 20u; y1b = 0; z1lbl = z1;
 \MT: rectangle(1)(20u,20v); % 1 is B
 \MTlabel(1lbl)"\aut B";
 \MT: x2r = x1l - 70u; y2b = y1t; z2lbl = z2;
 \MT: rectangle(2)(20u,20v); % 2 es M
 \MTlabel(2lbl)"\aut M";
 \MT: z3o = (x1r+5u,y1); z3d = (x2l,3/4[y2b,y2t]);
 \MT: forkback(3,3o,3d)(h,10u,10u);
 \MT: x3lbl.l = x3o; y3lbl.t = y3o - jot;
 \MTlabel(3lbl)"\no m";
 \MT: z4o = (x1r,y1); z4d = (w,y1); arrow(4o,4d);
 \MT: z6o = (0,1/4[y1b,y1t]); z6d = (x1l, y6o); arrow(6o,6d);
 \MT: z7o = (0,2/4[y1b,y1t]); z7d = (x1l, y7o); arrow(7o,7d);
 \MT: y6lbl.t = y6.o - jot; y7lbl.b = y7.o + jot; x6lbl = x7lbl = 5u;
 \MTlabel(6lbl)"\no v"; \MTlabel(7lbl)"\no n";
 \MT: z8d = (x2l,1/4[y2b,y2t]); z9d = (x2l,2/4[y2b,y2t]);
 \MT: z8m = z8d - (10u,0); z9m = z9d - (10u,0);
 \MT: z8o = (10u,y6o); fork(8o,8m,8d);
 \MT: z9o = (x8o,y7o); fork(9o,9m,9d);
 \MT: pickup thick_pen;
 \MT: z11 = z2 + (40u,0); z11lbl = z11; rectangle(11)(20u,20v);
 \MTlabel(11lbl)"\aut S";
 \MT: pickup med_pen;
 \MT: z12o = (x2r,y2); z12d = (x11l,y11); arrow(12o,12d);
 \MT: x12lbl = 1/2[x12o,x12d]; y12lbl.b = 1/2[y12o,y12d] + jot;
 \MTlabel(12lbl)"\no r";
 \MT: z13o = (x11r,y11); z13m = z13o + (5u,0);
 \MT: z13d = (x1l,3/4[y1b,y1t]); z13n = z13d - (10u,0);
 \MT: arrowww(13o,13m,13n,13d);
 \MT: x13lbl.l = x13m; y13lbl.b = y13m + jot;
 \MTlabel(13lbl)"\no b";
\MTendchar;
\box\MTbox
$$

Los datos~$\no r$ sirven para que el {\modelador} comunique al
{\simulador} cómo es la {\realidad}. Como la {\realidad} es un autómata,
los datos~$\no r$ especifican un comportamiento, por lo que son
programa, véase ^>El comportamiento>. Así que el {\simulador} recibe un
programa~$\no r$ que describe el comportamiento del {\universo} externo,
y en respuesta entrega otro programa~$\no b$ que describe cómo ha de ser
el comportamiento del propio {\cuerpo}.


\Section La lógica interna

El {\aprendiz} ha de tener varias representaciones posibles, cuantas más
mejor, del {\universo} exterior, que puede ser de cualquier modo,
porque, cuantas más tenga, más probable será que disponga de una que se
comporte hasta el momento como el {\universo}, y así pronostique
probablemente mejor, y sirva como {\realidad}. Es decir, el {\aprendiz}
tiene que disponer de un sistema de representación interno al que
denominaremos ^|lógica interna|. Esta lógica interna también tiene que
representar internamente los comportamientos de su {\cuerpo} para poder
simular su efecto, lo que explica la existencia de mapas somáticos_{mapa
somático} en los cerebros_{cerebro} de los aprendices.

Como en el ^{álgebra automática} tanto el {\universo} como el {\cuerpo}
son autómatas_{autómata} finitos, la lógica interna del {\aprendiz} ha
de ser capaz de representar autómatas finitos, o
comportamientos_{comportamiento}, y cuantos más, mejor.


\Section El problema del aprendiz

El {\simulador} tiene que resolver un problema similar al problema de la
supervivencia pero, en vez de ser contra cualquier universo, $\forall
\aut U$, es contra el mejor modelo encontrado por el {\modelador}, modelo
que denominamos {\realidad}. Este problema, que denominaremos ^|problema
del aprendiz|, no es aparente_{problema aparente}, ya que el
{\simulador} cuenta con la {\realidad} como ^{información}.

El problema del aprendiz no es aparente, porque la apariencia se queda
en el problema al que se enfrenta el {\modelador}. Si olvidamos esto,
podemos confundir la {\realidad} con el {\universo} exterior, pecado que
denominaremos ^{logicismo}. Es un pecado porque, aunque la {\realidad}
haya pronosticado hasta ahora con exactitud, nunca podremos estar
seguros de que el siguiente pronóstico será acertado ya que el universo
sigue siendo absolutamente desconocido, o sea, puede ser cualquiera,
$\forall \aut U$. El {\universo} puede ser, por ejemplo, aquél que se
comporta tal como la {\realidad} hasta el instante siguiente, en que
dejará de comportarse como ella. Otra consecuencia de este argumento es
que no es posible verificar si se cumple, o no se cumple, la ^{condición
del modelador}.

Pero, aunque sea un pecado, el {\simulador} trabaja bajo la hipótesis
logicista, esto es, como si la {\realidad} fuera el {\universo}
exterior, porque no tiene otra hipótesis mejor.


\Section Comparación de aprendices

Tanto el {\aprendiz} resolutivo formal como el aprendiz evolutivo de
entrada, visto entre _>El aprendiz> y _>La realidad del aprendiz es
cambiante>, modelan la realidad, y ambos prevén_{previsión} el futuro,
por lo que la relación entre ellos es clara. El aprendiz evolutivo es un
caso particular del {\aprendiz} resolutivo, porque el primero utiliza
una realidad de objetos, mientras que en el segundo no se imponen
requisitos a la {\realidad}. Así, por ejemplo, el ^{logicismo}, que
apareció al estudiar el {\aprendiz} formal, toma la forma del
^{objetivismo} cuando la realidad es objetiva.

Para demostrar la correspondencia que existe entre ambos aprendices,
hemos señalado, sobre el diagrama del aprendiz evolutivo mostrado en
^>La simulación>, las partes del {\aprendiz} formal que realizan el
tratamiento de los datos representado por cada flecha.
$$\hbox{Fenómeno}
   \underbrace{\strut
    \base{$\aut M\;\;$\cr$\longrightarrow\;$}
    \base{\vrule width0pt depth2pt$\aut S$\cr \onitself{\strut Objeto}}
    \base{$\aut B$\cr$\;\longrightarrow$}}_{\hbox{\strut Aprendiz}}
  \hbox{Acción}
$$


\Section La doble resolución

Para dar el siguiente paso en la ^{resolución} del ^{problema aparente},
hemos de volver al comienzo de dicha resolución. Entonces vimos, en ^>El
problema aparente>, que la manera de atacar un problema aparente, que no
tiene una solución definitiva, consiste en intentar varias resoluciones
pasando ^{información} de las ya efectuadas a las todavía por efectuar.
Lo que nos interesa ahora es que, dado que el problema aparente no tiene
una solución definitiva, su proceso de resolución consiste en diseñar
resoluciones cada vez mejores con la información obtenida de anteriores
resoluciones y, concretamente, el {\mecanismo}, el {\adaptador} y el
{\aprendiz} son resolutores, y no soluciones.

Por esta razón hay dos niveles en la resolución del problema aparente.
El nivel superior es el efectuado por la ^{resolución} general del
problema aparente, que se corresponde con la ^{evolución} darviniana, y
para el que toda la ^{vida}, al completo, ha de considerarse un único
ente resolutor; como propone ^[Lovelock]^(Lovelock1979). El nivel
inferior corresponde a la resolución que cada organismo vivo individual
ejecuta, ya que cada uno es un resolutor.


\Section El conocedor formal

El {\mecanismo}, el {\adaptador} y el {\aprendiz} son resolutores. Cada
uno de ellos resuelve de un modo, es decir, busca, de una manera
concreta, un comportamiento que solucione el problema. Y así como el
{\adaptador} mejoraba al {\mecanismo}, simplemente, porque era capaz de
más comportamientos, el ^|conocedor|~$\aut A_3$, que así llamaremos al
siguiente resolutor del problema aparente formalizado, será capaz de más
maneras de resolución.

Como el {\conocedor} es capaz de resolver de varias maneras, podemos
dividirlo en dos partes:
\point una ^|mente|~$\syn M$ que es capaz de resolver de varios modos, y
\point una ^|inteligencia|~$\syn A$ que decide qué modo de resolver ha de
ejecutarse en cada momento.

\noindent Para que el {\conocedor} mejore al {\mecanismo},
al {\adaptador} y al {\aprendiz}, es suficiente que su {\mente} sea
capaz de resolver como cada uno de ellos, y que la {\inteligencia}
satisfaga la ^{condición de la inteligencia}, esto es, que elija la
manera de resolver del {\mecanismo} si el {\mecanismo} soluciona, la del
{\adaptador} si éste soluciona y, si el {\aprendiz} soluciona, la del
{\aprendiz} (\EPA6).
$$\hbox{Problema}\,
   \underbrace{\strut
    \base{{\frakx A}$\;\;$\cr $\longrightarrow\;$}
  \hbox{Resolución}
    \base{{\frakx M}\cr $\;\longrightarrow$}}_{\hbox{%
     Conocedor$\,{\cal A}_3$}}
  \,\hbox{Solución}
$$

El diseño de la {\mente} está perfectamente especificado y, en último
caso, la {\mente} se podría construir simplemente agregando el
{\mecanismo}, el {\adaptador} y el {\aprendiz} y completando el agregado
con un selector que permitiera elegir uno de ellos. La tarea de la
{\inteligencia} consistiría, precisamente, en manejar el selector para
elegir uno de los tres. En resumen, disponemos de una {\mente} que
permite al {\conocedor} funcionar a voluntad como un {\mecanismo}, como
un {\adaptador} o como un {\aprendiz}, pero, ¿cómo debería manejarse el
selector?, es decir, ¿cómo diseñar la {\inteligencia}?

Como en el caso del {\gobernador}, véase ^>La previsión>, la
{\inteligencia} del {\conocedor} puede elegir la resolución, o bien
mecánicamente, o bien por tanteo_{tantear}. El tanteo no nos asegura que
el {\conocedor} mejore al {\mecanismo}, al {\adaptador} y al
{\aprendiz}. Y, por el otro lado, podría pensarse que puesto que hemos
demostrado que el {\aprendiz} es mejor que el {\adaptador}, y éste es
mejor que el {\mecanismo}, debería preferirse siempre el funcionamiento
como {\aprendiz}. Pero hemos de recordar que las mejoras estaban, en
cada caso, condicionadas al cumplimiento de unos determinados
requisitos. De manera que la principal tarea de la {\inteligencia} será
comprobar si se cumplen, o no, la ^{condición del gobernador}, para
discriminar entre mecanización y adaptación, y la ^{condición del
modelador}, para discriminar entre adaptación y aprendizaje.


\Section La inteligencia

La ^{condición del gobernador} discrimina entre el {\mecanismo} y el
{\adaptador}. Recordemos que el {\adaptador} mejora al {\mecanismo} si
cumple la condición del gobernador, o sea, si el {\adaptador} se
comporta como el {\mecanismo} cuando éste es solución en un {\universo}.
Sucede, pues, que en tales circunstancias el {\adaptador} y el
{\mecanismo} tienen idéntico comportamiento, siendo más sencillo éste
último. De aquí se deduce la primera regla de la {\inteligencia} del
{\conocedor}. La {\inteligencia}, al advertir que un comportamiento
mecanizado es solución, aplicará ese comportamiento \hbox{mecanizado}
para evitar otros cálculos más costosos que, funcionando como
{\adaptador} o como {\aprendiz}, tendría que efectuar.

Si, por el contrario, ningún comportamiento mecanizado soluciona, caso
que describiremos inexactamente como de condición del gobernador
insatisfecha, entonces se impone una resolución más compleja, ya sea
como {\adaptador} o como {\aprendiz}. En este caso la discriminación
depende de la ^{condición del modelador}. Porque, si se cumple la
condición del modelador, o sea, si la {\realidad} encontrada por el
{\modelador} prevé_{previsión} con la suficiente precisión, entonces le
conviene al {\conocedor} funcionar como {\aprendiz}. Pero, si no se
cumple la condición del modelador, es decir, si los pronósticos de la
mejor {\realidad} encontrada no son fiables, entonces le es mejor
prescindir de ellos y funcionar como un {\adaptador}. Y ésta es la
segunda regla de la {\inteligencia} del {\conocedor}.

La ^{sed}, que indica que el comportamiento actual no soluciona, es un
ejemplo de condición del gobernador insatisfecha. Y la ^{perplejidad} es
un ejemplo de condición del modelador incumplida. Ambos sentimientos, al
ser originados por condiciones deseables insatisfechas, son dolorosos,
pero la sed es corporal y la perplejidad mental. Descubrimos así dos
tipos de sentimientos: los sentimientos corporales, así calificados
porque dependen de la bondad, o maldad, de los comportamientos que
ejecuta el {\cuerpo}, y los sentimientos mentales, que así adjetivamos
porque dependen de la bondad, o maldad, de las resoluciones que realiza
la {\mente}. De modo que el ^{sentimiento} es un complejo que integra
información interna sobre el estado corporal y sobre el estado mental.

Podemos decir que esta información se organiza en tres mapas: el ^{mapa
somático} que representa al {\cuerpo}, el ^{mapa mental} que representa
a la {\mente}, y la {\realidad}, que es el mapa que representa al
exterior. Para que los tres mapas sean útiles a la {\inteligencia}, han
de estar convenientemente relacionados. A la ^{información} que
cohesiona e integra los distintos mapas, mental y corporal, internos y
externo, y que es fundamental para el funcionamiento unitario del
{\conocedor}, la denominamos ^{significado}.

No entraremos aquí en más detalles, como la interesante enfermedad de
^[Camus], porque la descripción completa podría desviar nuestra atención
de lo principal y porque, en cualquier caso, si usted lo desea, puede
encontrarla en \EPA{6.4}.


\Section Comparación de conocedores

La comparación de los conocedores mantiene la tendencia observada en las
anteriores comparaciones entre la resolución formal del problema
aparente y la evolución del camino de entrada, véanse _>Comparación de
adaptadores> y _>Comparación de aprendices>: el {\conocedor} formal es
más general que el conocedor evolutivo presentado entre _>El conocedor>
y _>La realidad del conocedor es semántica>. Ambos son capaces de
resolver de varios modos, y ésta es la esencia del conocedor. Pero, al
describir al conocedor evolutivo en el camino de entrada, nos fijamos en
que, de las distintas maneras en las que se puede usar la realidad, una
consiste en usarla entera y las otras en usar una parte, y vimos, por
ejemplo, como la sed podía ser un subproblema del problema de la
supervivencia que el conocedor evolutivo podía afrontar. En el caso del
{\conocedor} formal no están limitadas las maneras de resolver.

No obstante, para que la comparación sea exacta, ha de tenerse en cuenta
que la realidad semántica del conocedor evolutivo, vista en ^>La
realidad del conocedor es semántica>, abarca en su correspondiente
{\conocedor} formal, además de la {\realidad} estricta, los mapas
somático_{mapa somático} y mental_{mapa mental}, y la relación entre
todos ellos que denominamos ^{significado}.

Como al investigar sobre los sentimientos del {\conocedor} formal en la
sección anterior, _>La inteligencia>, descubrimos que la {\inteligencia}
recibe información interna, tanto corporal como mental, y externa,
resulta que el ^{sistema emocional}, que se corresponde con la
{\inteligencia} del {\conocedor} formal, debería estar, en el diagrama
del conocedor evolutivo, al final de tres flechas, que no están
dibujadas porque complicarían la representación. Cada una de estas tres
flechas tendría su origen en una de las tres flechas del diagrama del
^{aprendiz}, o sea, que estas nuevas flechas desde flechas
representarían datos de una nueva capa.


\Section La mejora de la mente

El {\conocedor} mejora a sus antecesores porque es capaz de varias
resoluciones, y no de una única. Pero, por la misma regla, un
{\conocedor} puede mejorar a otro si su {\mente} es capaz de más maneras
de resolver. Luego, aumentar la versatilidad de la {\mente} es una línea
de mejora resolutiva, en principio cuantitativa, que seguramente
antecedió a la siguiente mejora cualitativa.


\Section El sujeto formal

El {\sujeto} es al {\aprendiz}, como el {\conocedor} es al {\adaptador},
estando el {\adaptador} y el {\aprendiz} en la capa de las soluciones, o
de los comportamientos, y el {\conocedor} y el {\sujeto} en la capa de
las resoluciones. Es decir, que así como el {\adaptador} era capaz de
varios comportamientos y el {\aprendiz} también, pero con la posibilidad
de prever el efecto de los comportamientos, el {\conocedor} es capaz de
varias resoluciones y el {\sujeto} también, pero con la posibilidad de
prever_{previsión} el efecto de las resoluciones. Diremos que el
{\sujeto} puede ^{razonar} las resoluciones.

Para poder prever el efecto de las resoluciones, es menester comprender
el problema que las resoluciones afrontan. De modo que el
^|sujeto|~$\aut A_4$ consta de tres partes: un {\inquisidor} que busca
la mejor representación del problema al que se enfrenta, una {\razon}
que busca la mejor resolución posible para el problema hallado por el
{\inquisidor}, y una {\mente} que resuelve de la manera dispuesta por la
{\razon} (\EPA7).
$$\hbox{Problema}\,
   \underbrace{\strut
    \base{{\frakx I}$\;\;$\cr $\longrightarrow\;$}
    \base{\vrule width0pt depth2pt{\frakx R}\cr \onitself{\strut Resolución}}
    \base{{\frakx M}\cr $\;\longrightarrow$}}_{\hbox{%
     Sujeto$\,{\cal A}_4$}}
  \,\hbox{Solución}
$$

\point La {\mente} del {\sujeto} ha de ser capaz de varias resoluciones,
cuantas más mejor, según hemos visto en la sección anterior, _>La mejora
de la mente>, pero por lo menos, para superar al {\conocedor}, todas las
de éste. Así como la {\mente} del {\conocedor} está especificada, así lo
está la del {\sujeto}, ya que en último término podrían ser iguales.

\point El ^|inquisidor|~$\syn I$ busca la mejor representación del
problema al que se enfrenta, representación que denominaremos ^|problema
del sujeto|, o simplemente ^|yo|~$\syn X$. Si el problema encontrado, el
{\yo}, fuera indistinguible del problema al que efectivamente se
enfrenta el {\sujeto}, entonces diríamos que se cumple la condición del
inquisidor.

\point La tarea de la ^|razón|~$\syn R$, buscar la mejor resolución
posible del problema del sujeto, está perfectamente especificada porque
es completamente interna al {\sujeto}. Es decir, que la determinación de
cuál es la mejor resolución para el \Mental problema$X$ encontrado por
el {\inquisidor}, de entre todas las resoluciones de las que es capaz la
{\mente}, puede hacerse, en último término, mediante una búsqueda
sistemática.

\noindent La ^{condición del inquisidor} es una condición suficiente
para que el {\sujeto} supere al {\conocedor}, porque, si se cumple, es
decir, si el {\inquisidor} encuentra un problema indistinguible del
problema al que se enfrenta, entonces la {\razon} del {\sujeto} puede
calcular por adelantado la bondad, o la maldad, de una resolución antes
de acometerla, y puede evitar, de este modo, sufrir los errores que el
{\conocedor} es incapaz de anticipar. Y esto es así, aunque sea
imposible verificar que la condición del inquisidor está definitivamente
satisfecha; es imposible porque el {\sujeto} se enfrenta a un problema
aparente.


\Section El sujeto simbólico

Para que el {\sujeto} pueda prever_{previsión} el efecto de las posibles
resoluciones sobre los problemas a solucionar, ha de ser capaz de
representar problemas y resoluciones, y para hacerlo ha de disponer de
una ^{lógica simbólica}, con ^{semántica} y ^{sintaxis} recursiva. Ahora
daremos estos dos pasos, pero de uno en uno.

Un primer paso para convertir la ^{lógica interna} del {\conocedor} en
una lógica simbólica consiste, como ya vimos en ^>La semántica y la
sintaxis>, en añadir una capa sintáctica sobre la lógica preexistente,
que denominaremos semántica por serlo la realidad del conocedor; véase
^>Comparación de conocedores>. Es decir, que la lógica del {\conocedor},
capaz de representar los comportamientos del {\universo} exterior y del
propio {\conocedor}, así como las condiciones que evalúa su
{\inteligencia}, se convierte en la capa semántica de la lógica del
{\sujeto}. Y sobre esta capa semántica aparece una capa sintáctica para
completar la lógica simbólica. Construida la lógica simbólica del
{\sujeto} de esta manera, sus soluciones de han de ser de la misma
naturaleza que las del {\conocedor}, y el {\aprendiz}, es decir,
autómatas_{autómata}~$\aut A$, o sea, comportamientos, lo que, más que
una limitación, es un requisito. A una lógica con semántica y sintaxis
la denominamos ^{lógica gramatical}.

Pero, como no vale cualquier sintaxis, es necesario dar un segundo paso.
Cuantos más problemas sea capaz de representar la lógica del {\sujeto},
más posible resulta que pueda representar el problema al que actualmente
se enfrenta, y además, dada la evolución de la {\mente} en creciente
versatilidad, vista en ^>La mejora de la mente>, es también necesario
que la lógica del {\sujeto} represente la mayor cantidad y variedad
posible de resoluciones. En estas circunstancias, y recordando que las
resoluciones son transformaciones sintácticas, como también vimos en
_>La semántica y la sintaxis>, es preciso que la sintaxis tenga la
máxima expresividad y, por consiguiente, ha de ser
recursiva_{recursividad}, es decir, la sintaxis ha de ser tal que en
ella puedan expresarse, incluso, las propias transformaciones
sintácticas. En conclusión, y puesto que un ^|simbolismo| es,
precisamente, cualquier lógica gramatical cuya sintaxis es recursiva,
resulta que la lógica del {\sujeto} ha de ser simbólica.


\Section La jerarquía de Chomsky

Para entender mejor el alcance de los simbolismos, con sus sintaxis
recursivas, conviene ubicarlos en la ^{jerarquía de gramáticas} de
^[Chomsky]. Intentaré explicar la situación sin descender a los detalles
más técnicos, pero, si juzga usted que no es así, puede saltarse toda la
excursión por la ^{teoría de la computación} y proseguir directamente en
^>El algoritmo>, en donde se resumen las conclusiones más importantes.
Otra posibilidad, que yo le recomiendo, es que se aficione usted a la
teoría de la computación, en la que puede introducirse más fácilmente
con la ayuda de un texto sólido como el de ^[Fernández] y ^[Sáez
Vacas]^(Fernández1987), el de ^[Carroll] y ^[Long]^(Carroll1989), o el
de ^[Arbib]^(Arbib1987).

Se denomina \Mental gramática$G$ al conjunto de reglas que permite
construir todas las expresiones sintácticas de un determinado \Mental
lenguaje$L$, que es como se define el conjunto de expresiones
sintácticas correctamente construidas. Es importante advertir que, con
esta definición técnica y contrariamente al uso común, \mental
lenguaje$L$ equivale a sintaxis, quedando excluida la semántica. De
manera que el primer paso en el análisis de una ^{expresión sintáctica}
consiste en determinar si pertenece, o no, al lenguaje, esto es, si está
correctamente construida, o si no lo está. Al mecanismo capaz de
determinar si una expresión concreta pertenece al \mental lenguaje$L$ se
le denomina ^{reconocedor}, y se dice que acepta_{aceptar} la expresión
si la reconoce como sintácticamente correcta.

La jerarquía de gramáticas de ^[Chomsky] identifica cuatro tipos de
lenguajes, que, repito, más propiamente deberían denominarse sintaxis,
cada uno de los cuales está asociado con un tipo de gramática y con un
tipo de reconocedor. La diferencia entre el tipo de lenguaje más
sencillo de la jerarquía, el \Mental lenguaje regular$L_3$, y el más
 \hbox{complejo},
el \Mental lenguaje gramatical$L_0$ no restringido_{lenguaje
no restringido}, es que un ^{autómata} finito puede reconocer con una
única lectura secuencial, esto es, sin necesidad de retroceder,
cualquier expresión sintáctica de un \mental lenguaje regular$L_3$,
mientras que para analizar una expresión sintáctica de un \mental
lenguaje gramatical$L_0$ necesita, en general, transformarla en otras
expresiones, cuyas longitudes no están limitadas, avanzando y
retrocediendo en la lectura y escritura de las expresiones según sea
menester para su análisis.

Como las longitudes de las expresiones intermedias no están limitadas,
un autómata que analice expresiones de un \mental lenguaje
gramatical$L_0$ no restringido tendrá que valerse de una cinta
potencialmente infinita para poder retenerla mientras la analiza, puesto
que la memoria del autómata finito es, por definición, finita. A un
autómata finito con una cinta infinita se le denomina {\TM}. La ^{cinta}
es, pues, otra memoria que la {\TM} utiliza específicamente para retener
las expresiones sintácticas mientras las va analizando. Al autómata
finito de la {\TM} se le denomina \Procesador$T$.
$$\hbox{Máquina de ^[Turing]~$\syn T$}\left\lbrace
  \vcenter{\hbox{Procesador~${\cal P}_{\syn T}$}
           \hbox{Cinta}}\right.
$$

Para notar que, si escribimos la expresión sintáctica~$\frak e$ en la
cinta de la {\TM} cuyo procesador es~${\cal P}_{\syn T}$ y lo dejamos
funcionar, cuando se pare encontraremos en la cinta la expresión
sintáctica~$\frak r$, usaremos la notación:
$${\cal P}_{\syn T}[{\frak e}] \rightarrow {\frak r} .$$
Si, por el contrario, al escribir la expresión $\frak x$, la {\TM} no
llegara a pararse, diríamos que $\frak x$ es una ^{paradoja}, y lo
anotaríamos:
$${\cal P}_{\syn T}[{\frak x}] \rightarrow \infty .$$

Dada una expresión cualquiera, el \corporal autómata finito$R_3$
reconocedor de un determinado \mental lenguaje regular$L_3$ siempre es
capaz de determinar si la expresión pertenece a él, o si no pertenece,
con una única lectura secuencial. En cambio, lo más que puede asegurarse
de la máquina de ^[Turing]~$\syn R_0$ reconocedora de un \mental
lenguaje gramatical$L_0$ es que puede que reconozca la expresión como
perteneciente a dicho lenguaje, que puede que reconozca que no pertenece
a él, o que puede que nunca termine de analizarla. Dicho de otro modo,
en los \mental lenguajes gramaticales$L_0$_{lenguaje gramatical} pueden
expresarse paradojas.

Este importante resultado, que está muy relacionado con el teorema de
^{indecidibilidad} de ^[Gödel]^(G\"odel1931), se debe a
^[Turing]^(Turing1936), es conocido como \latin{the halting problem}, y
lo veremos en más detalle en _>La paradoja reflexiva>. Es como si la
atemporalidad, o reversibilidad, de las expresiones sintácticas no
restringidas, que pueden ser examinadas sin limitaciones avanzando o
retrocediendo, fuera la culpable de las paradojas. Y sospecho, en base a
que no se podría ver el tiempo sino desde una lógica atemporal, que aquí
se encuentra la esencia del ^{tiempo}, pero el vértigo me impide seguir
investigando esta cuestión ya examinada en ^>Lo permanente es lo
sintáctico>. Además, nos distraería de otro descubrimiento aún más
fundamental del mismo ^[Turing] de 1936.


\Section La máquina universal de Turing

Existe un tipo de máquina de ^[Turing], como ya anunciamos en ^>El
comportamiento>, que se llama {\UTM} y que es capaz de comportarse como
cualquier {\TM}. Más precisamente, una {\UTM} interpreta una parte de la
^{expresión sintáctica}, parte que denominaremos \Mental
algoritmo$P_{\syn T}$, como la descripción de una determinada {\TM} a
imitar, que puede ser cualquiera, de tal suerte que el resultado de
analizar la otra parte de la expresión, los llamados ^{argumentos} o
\Mental parámetros$d$, es, en todos los casos, el mismo que obtendría la
{\TM} imitada. O sea:
$${\cal P}_{\syn U}[{\syn P}_{\syn T}({\syn d})] \equiv
  {\cal P}_{\syn T}[{\syn d}] .$$
Es sorprendente que la máquina de ^[Turing] a imitar pueda ser
cualquiera, incluida la propia {\UTM}. Que el imitador pueda imitarse a
sí mismo parece lo más sencillo; sin embargo, el imitador es imitador
porque imita a alguien, de manera que, en este caso, una parte de los
\mental argumentos$d$ son el \mental algoritmo$P'$ que describe la máquina
que el imitador imitado imita. ¿No está claro?
$${\cal P}_{\syn U}[{\syn P}_{\syn U}
( \underbrace{{\syn P'}({\syn d'})}_{\hbox{\frak d}})] \equiv
  {\cal P}_{\syn U}[\underbrace{{\syn P'}({\syn d'})}_{\hbox{\frak d}}]
  \equiv
  {\cal P}'[{\syn d'}] .$$

Sucede, pues, que alcanzada la ^{complejidad} de la {\UTM}, que no es
infinita porque su \Procesador$U$ sigue siendo un autómata finito, ya
disponemos del máximo poder de análisis sintáctico que es posible
alcanzar. Por compleja que sea la {\TM} a imitar, la {\UTM} puede
imitarla. La clave consiste en poder representar sintácticamente al
propio \procesador$T$ sintáctico, porque el \mental algoritmo$P_{\syn
T}$ representa efectivamente la transformación sintáctica que tal
procesador acomete. Así que, dentro de los \mental lenguajes
gramaticales$L_0$_{lenguaje gramatical}, llamaremos \Mental lenguaje
universal$L_{\syn U}$ o, lo que es lo mismo, \Mental sintaxis
recursiva$L_{\syn U}$, a todo aquél cuyo reconocedor sea una {\UTM}.
$$ {\syn L}_{\syn U} = \hbox{Lenguaje universal}
                     = \hbox{Sintaxis recursiva} $$

Decimos que el {\UP}, esto es, el procesador de una {\UTM}, es un
^{motor sintáctico} porque es capaz de ejecutar cualquier transformación
sintáctica.
$${\cal P}_{\frak U}=\hbox{Procesador universal}=\hbox{Motor sintáctico}$$


\Section La expresividad

Hay que distinguir dos tipos de relación entre conjuntos que pueden
aplicarse a los lenguajes: la inclusión, utilizada en la jerarquía de
gramáticas de ^[Chomsky], y que relaciona dos conjuntos de lenguajes, y
la ^{expresividad}, que relaciona dos lenguajes, entendiendo el lenguaje
como el conjunto de sus expresiones sintácticas.

Por ejemplo, el lenguaje que sólo acepta la secuencia~$\frak abc$ es un
\Mental lenguaje regular$L_3$ porque hay un autómata finito que sólo
acepta tal secuencia, y también es un \Mental lenguaje gramatical$L_0$,
porque también hay una
 máquina de ^[Turing]_{máquina de \string\string\string\vperson[Turing]}
que solamente acepta dicha ^{expresión sintáctica}. Por razonamientos
como el anterior se concluye que todos los \mental lenguajes
regulares$L_3$ son \mental gramaticales$L_0$ y, en consecuencia, el
conjunto de los lenguajes regulares~$\{ {\syn L}_3 \}$ está contenido, o
incluido, en el conjunto de los lenguajes gramaticales~$\{{\syn L}_0\}$:
$$ \{ {\syn L}_3 \} \subset \{ {\syn L}_0 \} .$$

Ocurre, en cambio, que ningún \Mental lenguaje universal$L_{\syn U}$
puede aceptar únicamente la secuencia $\frak abc$, aunque todos ellos
pueden aceptar una versión ampliada. La posibilidad de ampliación exige
que se acepten otras secuencias; veamos todo esto en más detalle.

Sea~${\cal P}_{\frak\!abc}$ el procesador de la máquina de ^[Turing] que
solamente acepta la expresión~$\frak abc$. Sea $\syn U$ una
 máquina universal de ^[Turing]_{máquina universal de
 \string\string\string\vperson[Turing]},
y sea ${\syn P}_{\frak abc}$ la expresión sintáctica que representa al
procesador~${\cal P}_{\frak\!abc}$ en $\syn U$. Con esta terminología
resulta que $\syn U$ aceptará la expresión~${\syn P}_{\frak\!abc}({\frak
abc})$:
$${\cal P}_{\syn U}[{\syn P}_{\frak abc}({\frak abc})] \equiv
  {\cal P}_{\frak\!abc}[{\frak abc}] \rightarrow \true .
$$
De manera que las expresiones ampliadas tienen dos partes: el
^{algoritmo}, en el ejemplo~${\syn P}_{\frak abc}$, y los ^{parámetros},
que son~$\frak abc$ en el ejemplo. Y ya podemos asegurar que la \Mental
sintaxis recursiva$L_{\syn U}$ acepta la expresión~${\syn
P}_{\frak\!abc}({\frak abc})$, que debe leerse: `lo que expresa~$\frak
abc$ en el lenguaje reconocido por~${\cal P}_{\frak\!abc}$'. Pero el
\mental lenguaje universal$L_{\syn U}$ acepta, además, otras
expresiones, por ejemplo
 ${\syn P}_{\syn U}({\syn P}_{\frak abc}({\frak abc}))$, porque:
$${\cal P}_{\syn U}[{\syn P}_{\syn U}({\syn P}_{\frak abc}({\frak abc}))]
  \equiv {\cal P}_{\syn U}[{\syn P}_{\frak abc}({\frak abc})] \equiv
   {\cal P}_{\frak\! abc}[{\frak abc}] \rightarrow \true .$$

Por esta razón decimos que los \mental lenguajes universales$L_{\syn
U}$ son más expresivos que los \mental regulares$L_3$, aunque no los
incluyen; $\forall{\syn L}_3,{\syn L}_{\syn U}$:
$$\eqalign{
   {\syn L}_3 &\prec {\syn L}_{\syn U} \cr
   \{ {\syn L}_3 \} &\not\subset \{ {\syn L}_{\syn U} \}  . \cr
 }$$

El \mental lenguaje universal$L_{\syn U}$ es el más expresivo de los
lenguajes con gramática porque puede expresar todo cuanto pueda expresar
cualquier otro \mental lenguaje gramatical$L_0$, ya que las
transformaciones sintácticas de este otro, sean éstas cuales sean,
pueden expresarse en la \mental sintaxis recursiva$L_{\syn U}$ e
interpretarse como tales. Y, en conclusión, ningún \mental lenguaje
gramatical$L_0$ puede ser más expresivo que un \mental lenguaje
universal$L_{\syn U}$; $\forall{\syn L}_0,{\syn L}_{\syn U}$:
$${\syn L}_0 \preceq {\syn L}_{\syn U} .$$

En cierto modo, los \mental lenguajes universales$L_{\syn U}$ son
demasiado expresivos. Son tan expresivos que, si la expresión~$\frak x$
es paradójica en cualquier \Mental lenguaje gramatical$L_0$, por ejemplo
en el reconocido por aquella {\TM} cuyo procesador es~${\cal P}_{\syn
T}$, entonces la expresión~${\syn P}_{\syn T}({\frak x})$ es paradójica
en la \Mental sintaxis recursiva$L_{\syn U}$:
$$ {\cal P}_{\syn U}[{\syn P}_{\syn T}({\frak x})] \equiv
   {\cal P}_{\syn T}[{\frak x}] \rightarrow \infty .$$
Esto demuestra que en todas las \mental sintaxis recursivas$L_{\syn U}$
hay paradojas.

Además, las paradojas_{paradoja} que pueden ser expresadas en un \Mental
lenguaje universal$L_{\syn U}$ son pertinaces, porque no es posible,
siquiera, reconocerlas a todas. Para probarlo, es necesario mostrar que
en una \mental sintaxis recursiva$L_{\syn U}$ pueden expresarse
paradojas reflexivas_{paradoja reflexiva}, o
autorreferentes_{autorreferencia}, como `esta frase es falsa', también
llamadas paradojas de ^[Epiménides]^(Northrop1944), un cretense que
dijo, según cuentan, que todo cuanto dicen los cretenses es mentira.


\Section La recursividad

La ^{referencia} permite usar, en las expresiones sintácticas, nombres
como abreviaturas de otras expresiones, generalmente más largas. A la
operación de dar un ^{nombre} a una expresión la denominamos
^{definición}. Así, por ejemplo, si escribimos las definiciones tras los
dos puntos, y siendo~$n$ el nombre de la expresión sintáctica~$\syn n$:
$$ {\cal P}_{\syn U}[{\frak e} n {\frak o} : n = {\frak n} ]
   \rightarrow
   {\cal P}_{\syn U}[{\frak eno} : n = {\frak n} ] .$$
Nos vale que las definiciones de los nombres sean fijas, o sea, que no
se puedan cambiar. Para probar que cualquier {\UTM} puede usar nombres
basta mostrar que existe una máquina de ^[Turing] capaz de sustituir un
nombre por una expresión. Es decir, basta mostrar que es posible diseñar
una máquina de ^[Turing] ^{diccionario}~$\syn D$, que, dado un nombre,
devuelve su expresión:
$$ {\cal P}_{\syn U}[{\syn P}_{\syn D}(n)] \equiv
   {\cal P}_{\syn D}[n] \rightarrow {\frak n} .$$
Merced a las definiciones, las \mental sintaxis recursivas$L_{\syn U}$
son extensibles_{extensibilidad}.

El otro requisito necesario para poder expresar paradojas reflexivas, o
autorreferentes, es que se puedan expresar sintácticamente las propias
transformaciones sintácticas, como es el caso en los \mental lenguajes
universales$L_{\syn U}$. Porque entonces se puede dar nombre al
^{algoritmo} que representa a una transformación sintáctica, y ese mismo
nombre puede aparecer en la definición del propio algoritmo, expediente
que se denomina ^|recursividad|, y que da nombre a las
\mental sintaxis recursivas$L_{\syn U}$_{sintaxis recursiva}.


\def\algStop{\inmmode$\syn H$}
\def\algPdox{\inmmode$\syn Z$}

\Section La paradoja reflexiva

De modo que ya podemos mostrar que, en un \Mental lenguaje
universal$L_{\syn U}$, es imposible reconocer todas las paradojas. Lo
probaremos por reducción al absurdo, es decir, examinaremos lo que
sucedería si existiera efectivamente un ^{algoritmo}~{\algStop} que
siempre se parara y que dijese de cualquier ^{expresión
sintáctica}~$\frak w$ si, escrita en la cinta, la {\UTM} se pararía, y
en este caso el resultado de {\algStop} sería {\true}, o no se pararía,
y entonces el resultado sería {\false}, y en donde $\syn D$ es un
^{diccionario} con definiciones:
$$\algStop \cases{
 {\cal P}_{\syn U}[{\algStop}({\frak w}) : {\syn D}] \rightarrow \true
   & si ${\cal P}_{\syn U}[{\frak w} : {\syn D}]$ se para; \cr
 {\cal P}_{\syn U}[{\algStop}({\frak w}) : {\syn D}] \rightarrow \false
   & si ${\cal P}_{\syn U}[{\frak w} : {\syn D}] \rightarrow\infty$ .\cr
}$$

Si existiera {\algStop}, entonces también podríamos definir otro
algoritmo~{\algPdox}, de la siguiente manera:
$$ {\algPdox}({\frak y}) =
  {\bf if\;} {\algStop}({\frak y})
  {\;\bf then\;} {\it loop\,forever}
  {\;\bf else\;} {\it stop}
  {\;\bf end\;} .$$
Para probar que, si {\algStop} fuera un algoritmo, podríamos definir
{\algPdox}, hay que mostrar que en una {\UTM} se pueden definir
algoritmos que utilizan otros algoritmos, lo que no es difícil dada su
universalidad, y que se puede definir un {\bf if}, para lo que basta ver
que es posible construir un {\TM} que lo hace. Demos estas cuestiones
por probadas.

¿Qué ocurriría si escribiéramos la expresión
${\algPdox}(Z):Z={\algPdox}(Z)$, que es autorreferente, en la cinta de
la {\UTM}? Si el algoritmo {\algStop} se comporta como anunciamos,
entonces sólo hemos de estudiar los dos casos posibles.
\point Si ${\algStop}({\algPdox}(Z)): Z={\algPdox}(Z)$ es {\true},
quiere decir, según la definición de {\algStop}, que la expresión
 ${\algPdox}(Z): Z={\algPdox}(Z)$
hará parar la {\UTM}, pero, según la definición de {\algPdox}, depende
de cómo resuelva la {\UTM} la expresión
 ${\algStop}(Z): Z={\algPdox}(Z) \rightarrow
  {\algStop}({\algPdox}(Z)): Z={\algPdox}(Z)$,
que estamos suponiendo que es {\true}, de manera que lo hará es
\latin{loop forever}, o sea, no parar.
\point Si, por el contrario, ${\algStop}({\algPdox}(Z)): Z={\algPdox}(Z)$
fuera {\false}, entonces, según la definición de {\algStop}, con
${\algPdox}(Z): Z={\algPdox}(Z)$ la {\UTM} no debería pararse, pero, por
ser {\false}, según la definición de {\algPdox} se ejecutaría la rama
{\bf else} y se pararía.

\noindent Lo que esta contradicción significa es que el
algoritmo~{\algStop} no puede existir tal como lo hemos definido y, por
lo tanto, que dentro de un lenguaje universal es imposible determinar
definitivamente si una expresión es paradójica, o si no lo es. Y con
esto queda probado que, en las sintaxis recursivas, las paradojas son
pertinaces.


\Section La sintaxis recursiva

Para despedir esta visita a la ^{teoría de la computación}, que con toda
propiedad podría denominarse ^{teoría de la sintaxis}, ubicaremos al
conjunto de los lenguajes universales_{lenguaje universal}, $\{ {\syn
L}_{\syn U} \}$, en el más general conjunto de los lenguajes
gramaticales_{lenguaje gramatical}, $\{ {\syn L}_0 \}$.

Podemos partir el conjunto de los lenguajes gramaticales~$\{ {\syn L}_0
\}$ en otros dos conjuntos disjuntos: el conjunto de los lenguajes
decidibles~$\{ {\syn L}_{\syn D} \}$ y el conjunto de los lenguajes
indecidibles_{lenguaje indecidible}~$\{ {\syn L}_{\syn I} \}$:
$$\eqalign{
 \{ {\syn L}_{\syn D} \} \cup \{ {\syn L}_{\syn I} \} &= \{ {\syn L}_0 \}\cr
 \{ {\syn L}_{\syn D} \} \cap \{ {\syn L}_{\syn I} \} &= \hbox{\O} . \cr
}$$
^[Carroll] y ^[Long]^(Carroll1989) notan~${\cal H}_{\Sigma}$ el conjunto
de los lenguajes decidibles,
 ${\cal H}_{\Sigma} = \{ {\syn L}_{\syn D} \}$,
que son los lenguajes reconocidos por las {\TMes} que siempre se paran,
y que ubican en la jerarquía de ^[Chomsky] entre los gramaticales no
restringidos~$\{{\syn L}_0 \}$ y los sensibles al contexto~$\{ {\syn
L}_1 \}$:
$$ \{ {\syn L}_1 \} \subset
   \{ {\syn L}_{\syn D} \} \subset
   \{ {\syn L}_0 \} .$$

En ningún \Mental lenguaje decidible$L_{\syn D}$ pueden expresarse
paradojas, porque todas las expresiones_{expresión sintáctica} son
decidibles. Por contra, en todos los \mental lenguajes
indecidibles$L_{\syn I}$ existen paradojas. Como también pueden
expresarse paradojas en todas las \mental sintaxis recursivas$L_{\syn
U}$_{sintaxis recursiva}, según demostramos en ^>La paradoja reflexiva>,
resulta que todos los \mental lenguajes universales$L_{\syn U}$ son
\mental indecidibles$L_{\syn I}$, aunque no todos los \mental lenguajes
indecidibles$L_{\syn I}$ son \mental universales$L_{\syn U}$, porque hay
{\TMes} que ni se paran siempre ni son universales:
$$ \{ {\syn L}_{\syn U} \} \subset
   \{ {\syn L}_{\syn I} \} \subset
   \{ {\syn L}_0 \} . $$

Entre los \mental lenguajes indecidibles$L_{\syn I}$ se encuentran,
también, aqué\-llos con errores; por ejemplo el lenguaje aceptado por
una {\TM} que únicamente no se para ante una secuencia de cien unos
consecutivos por, digamos, un despiste al diseñar el estado
correspondiente a los cien unos.


\Section El algoritmo

En ^>La semántica y la sintaxis>, definimos una ^{lógica simbólica} como
aquélla capaz de representar problemas, resoluciones y soluciones,
valiéndose de dos capas: la sintaxis y la semántica. La ^{semántica}
contiene las soluciones y la ^{sintaxis} los problemas y las
resoluciones. Las resoluciones toman el ^{problema} expresado
sintácticamente y lo van transformando sintácticamente hasta alcanzar la
expresión sintáctica de una ^{solución}. De modo que la ^{resolución} es
una transformación sintáctica.

Llamamos ^|algoritmo| a la expresión de una transformación sintáctica
que, en principio, puede ser una ^{expresión sintáctica} o
meta-sintáctica. La primera alternativa conduce, como hemos visto entre
^>La jerarquía de Chomsky>, y ^>La sintaxis recursiva>, a las
\mental sintaxis recursivas$L_{\syn U}$_{sintaxis recursiva}, capaces de
la máxima ^{expresividad}, pero que no pueden evitar las paradojas. Las
paradojas_{paradoja} son expresiones sintácticas sin significado,
inconclusivas, irresolubles, esto es, son resoluciones que no alcanzan
la solución. Así que ^[Russell] intentó, con su ^{teoría de tipos}, la
segunda alternativa para evitar la ^{paradoja reflexiva} que él mismo
había descubierto en la teoría de los conjuntos, véase
^[Quine]\footnote{_(Quine1940), página~163 y siguientes.}:
 $$R = \{ x?\; x \not\in x\} \Longrightarrow
  ( R \in R \Longleftrightarrow R \not\in R ) .$$
Pero la ^{lógica tipada} resultante es complicada, lo cual induce a
errar, limita la expresividad de la lógica y, lo que es peor, necesita
de un número ilimitado de meta-meta-\dots-sintaxis, así que es, ella
misma, paradójica.

Es mejor tolerar las paradojas y usar sintaxis recursivas, que son más
sencillas y expresivas, porque, en la práctica, ni la ^{cinta} de la
{\TM} es infinita, ni el ^{tiempo} disponible para alcanzar una solución
es ilimitado, de manera que las resoluciones que precisan más cinta de
la disponible o demasiado tiempo, aunque fueran capaces de alcanzar una
solución en otras circunstancias, son tan inútiles o perjudiciales como
las paradojas. En definitiva, las paradojas no son peores que las
resoluciones malas.


\Section La razón

La tarea del {\inquisidor} es describir con la mayor precisión posible
el problema al que se enfrenta el {\sujeto}. La {\razon} recibe del
{\inquisidor} la representación del \Mental problema$X$, representación
que es necesariamente sintáctica, y la {\razon} produce, como resultado,
la representación de la resolución, o sea, el ^{algoritmo} que ha de
ejecutar la {\mente}, representación que también es sintáctica. Luego,
si la {\razon} ha de tener la máxima generalidad, según concluimos en
^>El sujeto simbólico>, entonces la {\razon} ha de ser un ^{motor
sintáctico}, o procesador universal~${\cal P}_{\frak U}$, capaz de
transformar cualquier ^{expresión sintáctica} en cualquiera otra, como
hemos visto en ^>La máquina universal de Turing>:
$${\frak R}={\cal P}_{\frak U} .$$
Esto significa que la ^{lógica interna} del {\sujeto} o, al menos, la de
su {\razon}, es una lógica simbólica, con semántica y \Mental sintaxis
recursiva$L_{\syn U}$.

Por fin, la {\mente} tiene que aplicar el algoritmo de resolución
propuesto por la {\razon} y obtener la solución, en forma de
comportamiento que pueda ejecutar el {\cuerpo}, para que, si todo ha ido
bien, solucione efectivamente el problema al que se enfrenta el
{\sujeto}.

En la semántica del ^{simbolismo} de la {\razon} del {\sujeto} tienen
^{significado}: los símbolos que se refieren a los recursos de la
{\mente}, como son los comportamientos del {\cuerpo}, las modelaciones
del {\modelador}, los pronósticos_{previsión} de la {\realidad} y las
simulaciones del {\simulador}; y los que aluden a las condiciones que la
{\razon} puede considerar, como son la bondad o maldad de los
comportamientos y de los pronósticos. Otros símbolos representan
conceptos de la ^{teoría del problema}, como, por ejemplo, la
^{libertad} del problema, notada `?', que no tiene significado, porque
indica a la {\razon} que la expresión sintáctica en la que se encuentra
está abierta, o sea, que no tiene cerrado su significado, y que,
consiguientemente, no está lista para ser pasada a la {\mente}.


\Section Comparación de yoes

Hemos cerrado un círculo en el ^{camino de salida}. Salimos del ^{yo} al
descubrir, en _>Yo estoy vivo>, que el yo no es todo el ^{sujeto}, sino
que el yo sólo es el ^{problema del sujeto}. El sujeto está vivo, es
parte de la ^{vida}, de manera que el problema del sujeto es parte del
^{problema de la supervivencia} que define la vida. El problema de la
supervivencia es un ^{problema aparente} que, concretado en el ^{tiempo}
y en el ^{espacio}, formalizamos, en _>El problema aparente
formalizado>, y resolvimos. Y, ahora, la resolución del problema
aparente formalizado nos lleva al {\sujeto} y, finalmente, al {\yo}.
Pero, para completar cabalmente el círculo, hay que establecer que el
{\yo} formal encontrado coincide con aquel yo originario del que
partimos para salir, en _>¿Qué soy yo?>, y que definimos como
^{libertad} para no morir, en _>Yo soy libertad para no morir>, y que
era sintáctico y paradójico, según vimos en _>Yo estoy en la sintaxis> y
_>Yo soy paradójico>.

El {\sujeto} formal encontrado coincide con el sujeto original, ya que
de éste solamente teníamos dos datos, véase ^>Yo estoy vivo>, y en ambos
coincide con el formal. Sabíamos que el sujeto original, como el
{\sujeto} formal, dispone de una ^{lógica simbólica}. Y sabíamos,
también, que el problema del sujeto original es su yo originario, lo
mismo que el problema del {\sujeto} formal es su {\yo} formal; lo mismo
siempre y cuando coincidan ambos yoes, lo que probaremos a continuación.

Para el {\sujeto} formal, el {\yo} formal resulta ser la mejor
representación que él mismo puede hacerse del problema al que se
enfrenta, que es el problema aparente de la supervivencia. Como la
libertad es inherente a todo problema, y la condición final del problema
de la supervivencia es vivir, resulta que el {\yo} formal podría
definirse de la misma manera que definimos el yo originario, esto es,
como libertad para no morir.

El {\yo} formal también es sintáctico, puesto que cualquier
representación de un problema ha de ser sintáctica, como ya sabemos,
véase ^>La semántica y la sintaxis>, porque ha de representar la
libertad, que está tautológicamente libre de significado.

En ^>El sujeto formal>, establecimos que la condición del inquisidor no
puede ser verificada concluyentemente, es decir, que la representación
de de un problema aparente, dada su naturaleza, nunca es definitiva, y,
por esta razón, el \Mental problema del sujeto$X$ formal ha de
mantenerse siempre abierto a revisión. Como un problema cambiante no
puede tener una solución definitiva, queda probado que el {\yo} formal
es paradójico.


\Section Comparación de sujetos

Las comparaciones de la sección anterior eran entre sujetos, y yoes, del
camino de salida, de modo que todavía no hemos comparado los sujetos del
camino de salida con sus homónimos del camino de entrada.

La característica esencial del {\sujeto} formal es su capacidad de
^{razonar}, es decir, de prever_{previsión} el resultado de las
diferentes maneras de resolver, y para ello le es imprescindible una
lógica simbólica en la que representar los problemas y las resoluciones,
además de las soluciones. El sujeto evolutivo, visto entre _>La palabra>
y _>El mundo del sujeto es simbólico>, disponía de una lógica simbólica,
así que ha de ser considerado como un caso específico de {\sujeto}
formal, con las peculiaridades que se derivan de su herencia darviniana.
Recordemos que la ^{sintaxis} del sujeto evolutivo se apoyaba en una
^{realidad} de cosas con ^{significado} heredada del conocedor, mientras
que de la sintaxis del {\sujeto} formal solamente podemos asegurar que
se sostiene sobre una capa ^{semántica} heredada del {\conocedor} en
donde han de estar las soluciones. Así, mientras en la sintaxis
evolutiva encontramos oraciones_{oración} con sustantivos_{sustantivo},
verbos_{verbo}, adjetivos_{adjetivo} y pronombres_{pronombre}, de la
sintaxis formal sabemos que ha de ser recursiva_{sintaxis recursiva},
${\syn L}_{\syn U}$, es decir, de máxima expresividad pero con paradojas
pertinaces, y que para tratar tales sintaxis es necesario un {\UP}, o
^{motor sintáctico}, que es el procesador de una {\UTM}.


\Section El bucle subjetivo

Habiendo llegado hasta el final del ^{camino de salida}, ya podemos
hacer apreciaciones globales. El camino de salida es circular_{bucle
subjetivo}. Parte del ^{yo}, definido como ^{problema}, entonces va al
^{sujeto} y, desde aquí, a la ^{vida}, definida como ^{problema
aparente}, en donde termina la primera parte, que es ciertamente de
salida. Pero, la ^{resolución} del problema aparente de la
supervivencia, que pasa por cinco etapas, termina en el {\sujeto} con su
{\yo}, así que esta segunda parte del camino de salida regresa al
principio, como mostramos en ^>Comparación de yoes>, y discurre en el
mismo sentido que el camino de entrada.
$$\vbox{\everycr={}\tabskip=0pt \lineskip=0pt
  \halign{&\hfil#\hfil\cr
   Yo& $\,\rightarrow\,$& Sujeto$\,$& \rightarrowfill& &
    $\,$Problema de la supervivencia\cr
   % $\Updownarrow$& &$\Updownarrow$& & &$\Updownarrow$\cr
   $\parallel$& &$\parallel$& & &$\parallel$\cr
   \frakx X& $\leftarrow$& ${\cal A}_4$& $\leftarrow$%
    ${\cal A}_3$$\leftarrow$${\cal A}_2$$\leftarrow$%
    ${\cal A}_1$$\leftarrow$& ${\cal A}_0$$\leftarrow$\hidewidth&
    Problema aparente\cr}}$$

\breakif2

Se completa así el círculo, y ahora podemos contemplar enteramente el
postulado fundamental de la ^{teoría de la subjetividad}, a saber, que
la vida, o lo que es lo mismo, el ^{problema de la supervivencia}, es un
^{problema aparente}; véase ^>El problema de la supervivencia>. Nos
valdremos de una observación general: en cualquier teoría que utilice
problemas para explicar, si algún concepto se corresponde con un
problema aparente, ha de ser un concepto primigenio que la teoría deje
indefinido, ya que no puede aportar información alguna sobre él. De la
observación se sigue que, tanto la necesidad de usar problemas para
explicar, como la elección de la ^{vida} como el concepto primitivo no
definido de la teoría de la subjetividad, son consecuencias de definir
el yo como libertad para no morir. Porque el yo, por ser libertad y
condición, es problema y, por ser la condición no morir, remite a la
vida. Remite a la vida porque el yo, dado que está definido, no puede
ser el concepto primigenio indefinido que sí puede ser la inefable vida.

Pero, como el camino es circular, quien lo prefiera puede ponerlo al
revés. Si se explica el yo a partir del problema aparente de la
supervivencia, entonces la consecuencia es que el yo ha de definirse
como libertad para no morir.

Por otra parte, la resolución del problema aparente alcanza el {\sujeto}
con su {\yo}, lo que prueba constructivamente que una teoría
problemática es suficiente para explicar la naturaleza del sujeto y del
yo.


\Section Los niveles

Las cinco etapas de la resolución del problema aparente pueden agruparse
en tres niveles. El {\mecanismo} no es más que el punto de partida y
forma, él solo, el nivel de referencia. El siguiente nivel, al que
pertenecen el {\adaptador} y el {\aprendiz}, aparece con el {\cuerpo},
que es capaz de comportarse como varios \corporal mecanismos$A_0$ y, de
este modo, podemos decir que incluye al nivel de referencia anterior
(\EPA2).
$$\hbox{Adaptador $\aut A_1$}\llave{
   Gobernador $\aut G$\cr
   Cuerpo $\aut B$\lopen\langle{Mecanismo $\aut A_0$}}$$
Por fin, el tercer nivel, en el que están el {\conocedor} y el
{\sujeto}, tiene su origen en la {\mente} que, al ser capaz de resolver
como los \corporal aprendices$A_2$, como los \corporal adaptadores$A_1$
y como los \corporal mecanismos$A_0$, contiene a los dos niveles que lo
anteceden (\EPA6).
$$\hbox{Conocedor $\aut A_3$}\llave{
   Inteligencia $\syn A$\cr
   Mente $\syn M$\lopen\langle{
    Aprendiz $\aut A_2$\cr
    Adaptador $\aut A_1$\cr
    Mecanismo $\aut A_0$}}$$

Dentro de cada nivel con dos etapas, la primera etapa engloba
externamente al nivel anterior y la segunda lo interioriza. Así, el
{\simulador} del {\aprendiz} contiene interiorizaciones de los
comportamientos de su {\cuerpo} y del exterior, y, por esto, la tarea
del {\modelador} es componer la {\realidad}, que es, precisamente, la
representación interior del comportamiento del exterior (\EPA3).
$$\hbox{Aprendiz $\aut A_2$}\llave{
   Gobernador $\aut G$\llave{
    Modelador $\aut M$ $\to$ Realidad $\aut R$\cr
    Simulador $\aut S$ [Cuerpo $\aut B$]}\cr
   Cuerpo $\aut B$\lopen\langle{Mecanismo $\aut A_0$}}$$
Y, similarmente, la {\razon} del {\sujeto} tiene las representaciones,
sintácticas y recursivas, de las resoluciones de su {\mente} y del
problema exterior, así que la tarea del {\inquisidor} es buscar el
problema al que se enfrenta, esto es, el problema del sujeto, o sea, el
{\yo}, que es, precisamente, la representación interna del problema
externo (\EPA7).
$$\hbox{Sujeto $\aut A_4$}\llave{
   Inteligencia $\syn A$\llave{
    Inquisidor $\syn I$ $\to$ Yo $\syn X$\cr
    Razón $\syn R$ [Mente $\syn M$]}\cr
   Mente $\syn M$\lopen\langle{
    Aprendiz $\aut A_2$\cr
    Adaptador $\aut A_1$\cr
    Mecanismo $\aut A_0$}}$$

Sucede que el {\sujeto}, que culmina el proceso resolutivo del problema
aparente, lo contiene completo. Porque en la {\razon} está interiorizada
la {\mente}, que incluye todo lo anterior, y por lo tanto, también
contiene al {\simulador}, que interioriza al {\cuerpo}.


\Section Las capas

La construcción del simbolismo en dos capas, vista en ^>La semántica y
la sintaxis>, y en ^>El sujeto simbólico>, que está en el origen de los
niveles de la resolución del problema aparente, nos permite descubrir
algunas correspondencias en el ^{mundo} del sujeto, presentado en ^>El
mundo>. El {\cuerpo} en la capa de los comportamientos, que es la de las
soluciones y que llamamos semántica, se corresponde con la {\mente} en
la capa de las resoluciones, que denominamos sintáctica. Y el {\yo} se
corresponde con la {\realidad}.
$$\vbox{\def\uc#1{\relax\uppercase{#1}}
 \def\:#1#2:#3#4.{\uc#1#2_{#1#2}& $\equiv$&\uc#3#4_{#3#4}\cr}
 \setbox0=\hbox{$\mathop{\cal A}\nolimits_4$ }
 \def\.#1#2 $#3#4$.#5#6 #7$#8#9$.{\uc#1#2_{#1#2}%
  \hbox to\wd0{\hfil$\mathop{\cal #3}\nolimits#4$}&
  $\equiv$&
  \hbox to\wd0{$\mathop{\frak #8}#9$\hfil}\uc#5#6_{#5#6} #7\cr}
 \halign{&\hfil#&\hfil\quad#\quad\hfil&#\hfil\crcr
 \.adaptador $A_1$.conocedor {$\aut A_3$}$E_1$.
 \.gobernador $G$.inteligencia $A$.
 \.cuerpo $B$.mente $M$.
 \.aprendiz $A_2$.sujeto {$\aut A_4$}$E_2$.
 \.modelador $M$.inquisidor $I$.
 \.simulador $S$.razón {${\cal P}_{\syn U}$}$R$.
 \.realidad $R$.yo $X$.
 \:semántica:sintaxis.
 \:comportamiento:problema.
 \:solución:resolución.
 \:programa:algoritmo.
 \:cosa:concepto.
 \:práctica:teoría.
 \:finito:infinito.
 \:física:metafísica.
 \:datos:información.
 \:cambio:permanencia.
 \:res extensa:res cogitans.
}}$$


\Section El mundo es un enigma

El {\inquisidor} ocupa el lugar más elevado del {\sujeto} que, a su vez,
es la cumbre del proceso resolutivo del problema aparente. Y la tarea
del {\inquisidor} es plantear preguntas, la primera ¿qué soy yo? Tal vez
por esto ^[Aristóteles]^(Aristóteles-IV) comenzó su ^<Metafísica>
declarando que ``todos los hombres tienen naturalmente el ^{deseo} de
saber''.

El sujeto es curioso_{curiosidad} porque entiende el mundo y sus
situaciones como problemas que hay que resolver. Para el sujeto, el
mundo es un enigma.


\endinput
